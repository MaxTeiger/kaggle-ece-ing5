{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "0yMQ61oGIquY",
    "outputId": "54cc84dd-6ce5-4e46-cacd-bc859f79e055"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "yB0DlJ18wIMg",
    "outputId": "bdc6a0d9-f787-40eb-81b2-9367dfe39a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Use the drive \"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_UnT9awhh7g2"
   },
   "source": [
    "## Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdHimIPxixs7"
   },
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Gn9QFYQd9HW"
   },
   "outputs": [],
   "source": [
    "def create_glove_wordmap(glove_zip_file = \"glove.6B.zip\",\n",
    "                         glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "                         ):\n",
    "  \n",
    "    from urllib.request import urlretrieve\n",
    "    #large file - 862 MB\n",
    "    if (not os.path.isfile(glove_zip_file) and\n",
    "        not os.path.isfile(glove_vectors_file)):\n",
    "        urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                    glove_zip_file)\n",
    "        \n",
    "    unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "\n",
    "    glove_wordmap = {}\n",
    "\n",
    "    with open(glove_vectors_file, \"r\") as glove:\n",
    "        for line in glove:\n",
    "            name, vector = tuple(line.split(\" \", 1))\n",
    "            glove_wordmap[name] = np.fromstring(vector, sep=\" \")\n",
    "\n",
    "    return glove_wordmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DK1H0E4d3BB"
   },
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence, wordmap, visualize=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "        \n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "            word = token[:i]\n",
    "            if word in wordmap:\n",
    "                rows.append(wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "            else:\n",
    "                i = i-1\n",
    "    \n",
    "    if visualize: return rows, words\n",
    "    else: return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDvTpS_xeBGT"
   },
   "outputs": [],
   "source": [
    "def visualize(sentence, wordmap):\n",
    "    \"\"\"\n",
    "        Visualize GloVe Embeddings in a sentence\n",
    "    \"\"\"\n",
    "    rows, words = sentence2sequence(sentence, wordmap, visualize=True)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEaU_7SQIycs"
   },
   "outputs": [],
   "source": [
    "def gen_csv(predicted, label_map, verbosity=False):\n",
    "    \"\"\"\n",
    "        Generate CSV with predicted results and\n",
    "        required form from the return of predict function and \n",
    "        the maping dictionnary {int: 'value'} \n",
    "    \"\"\"\n",
    "    import csv\n",
    "    from google.colab import files\n",
    "    predicted_results = np.argmax(predicted, axis=1)\n",
    "    if verbosity: print(label_map)\n",
    "    dict_data=[]\n",
    "    for i, v in enumerate(predicted_results): \n",
    "      d={'index':i, 'label':label_map[v]}\n",
    "      dict_data.append(d)\n",
    "    if verbosity: print(dict_data)\n",
    "    csv_file='results.csv'\n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=['index', 'label'])\n",
    "            writer.writeheader()\n",
    "            for data in dict_data:\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "    files.download('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1ghnGPovBVY"
   },
   "outputs": [],
   "source": [
    "def data_from_csv(path, dev_mode=True, n_dev = 5000):\n",
    "    \"\"\" \n",
    "        retrieve data from CSV in a pandas.Dataframe\n",
    "    \"\"\"\n",
    "    # Entire dataset for training/validation\n",
    "    dataset = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "    # Dataset for dev\n",
    "    # less items to speed up computations\n",
    "    if dev_mode: \n",
    "      dataset = dataset.sample(n=n_dev)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqHgaKN5ynCd"
   },
   "outputs": [],
   "source": [
    "def process_dataset(dataset, training=True, map_dict={'neutral':2, 'entailment':1, 'contradiction':0}):\n",
    "    \"\"\"\n",
    "        Return a preprocessed dataframe from the dataset sent in args\n",
    "        If the dataset doesn't have a label column set training to False\n",
    "    \"\"\"\n",
    "    import string # to get rid of the punctuation\n",
    "\n",
    "    n_dataset = dataset.copy()\n",
    "\n",
    "    n_dataset['sentence_1'] = [x.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "                             for x in dataset.sentence_1.values]\n",
    "\n",
    "    n_dataset['sentence_2'] = [x.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "                             for x in dataset.sentence_2.values]    \n",
    "\n",
    "    n_dataset['sentence_1'] = [np.array(sentence2sequence(x, glove_wordmap)) \\\n",
    "                             for x in dataset.sentence_1.values]\n",
    "\n",
    "    n_dataset['sentence_2'] = [np.array(sentence2sequence(x, glove_wordmap)) \\\n",
    "                             for x in dataset.sentence_2.values]\n",
    "\n",
    "    if training:\n",
    "        n_dataset['target'] = n_dataset['label'].replace(map_dict)\n",
    "\n",
    "    return n_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaNLALzshyzq"
   },
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9cIZ8S9FLQg9",
    "outputId": "4803e1c6-9257-4792-8e9b-9261365d964c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "# Import `Dense` from `keras.layers`\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten, \\\n",
    "                          Bidirectional, Concatenate, GlobalAveragePooling1D\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JnC2S4Uk84e"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJVV4UORiDu4"
   },
   "source": [
    "#### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AW2jsNlWkuWm"
   },
   "outputs": [],
   "source": [
    "# Retrieve Embedded Vectors from Glove\n",
    "glove_wordmap = create_glove_wordmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ye2ZEmhb193g"
   },
   "outputs": [],
   "source": [
    "# Retrieve Dataset from CSV \n",
    "path_train=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_train.csv\"\n",
    "path_test_no_label=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_test_no_labels.csv\"\n",
    "\n",
    "dataset = data_from_csv(path_train, n_dev=5000, dev_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UGYQa_az3NMj",
    "outputId": "6a487a07-acfe-4f44-c182-539e38cb5929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ! \n"
     ]
    }
   ],
   "source": [
    "map_dict={'neutral':2, 'entailment':1, 'contradiction':0}\n",
    "dataset_processed = process_dataset(dataset, map_dict=map_dict)\n",
    "print(\"Processed ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "MKp_PadTDOsM",
    "outputId": "f883dc6e-c121-4ba3-a415-2834ad86cceb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1.0997, -1.0101, -0.44778, -0.014276, 0.2596...</td>\n",
       "      <td>[[0.15882, -0.27394, 0.25375, 0.76122, 0.30715...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0010919, 0.33324, 0.35743, -0.54041, 0.82...</td>\n",
       "      <td>[[-0.0010919, 0.33324, 0.35743, -0.54041, 0.82...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.31474, 0.41662, 0.1348, 0.15854, 0.88812, ...</td>\n",
       "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.68938, -0.10644, 0.17083, -0.37583, 0.7517...</td>\n",
       "      <td>[[0.53074, 0.40117, -0.40785, 0.15444, 0.47782...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.80924, -0.030977, 0.5102, -0.75298, 0.490...</td>\n",
       "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         sentence_1  ...       label target\n",
       "0      0  [[1.0997, -1.0101, -0.44778, -0.014276, 0.2596...  ...     neutral      2\n",
       "1      1  [[-0.0010919, 0.33324, 0.35743, -0.54041, 0.82...  ...  entailment      1\n",
       "2      2  [[0.31474, 0.41662, 0.1348, 0.15854, 0.88812, ...  ...  entailment      1\n",
       "3      3  [[0.68938, -0.10644, 0.17083, -0.37583, 0.7517...  ...  entailment      1\n",
       "4      4  [[-0.80924, -0.030977, 0.5102, -0.75298, 0.490...  ...     neutral      2\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZQ1YAEpeW_S"
   },
   "outputs": [],
   "source": [
    "# On pad ici, sinon ca fait planter la RAM quand on utilise toutes les \n",
    "# lignes du CSV\n",
    "pad1 = pad_sequences(dataset_processed['sentence_1'].values, maxlen=80)\n",
    "pad2 = pad_sequences(dataset_processed['sentence_2'].values, maxlen=80)\n",
    "\n",
    "X = [pad1, pad2]\n",
    "y = dataset_processed['target'].values\n",
    "\n",
    "# (Nb inputs, nb words, nb dim)\n",
    "assert X[0][0].shape == (80, 50), \"Check the shape of your data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZqf4e9RguCp"
   },
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908
    },
    "colab_type": "code",
    "id": "U74diBpDfw9W",
    "outputId": "2137a405-f8ee-48af-e062-b5aeb4831260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 80, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80, 512)      628736      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 80, 512)      0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 80, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          328192      dropout_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             multiple             0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "                                                                 dropout_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           dropout_2[2][0]                  \n",
      "                                                                 dropout_2[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            387         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 965,571\n",
      "Trainable params: 965,571\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(80,50))\n",
    "inputs2 = Input(shape=(80,50))\n",
    "\n",
    "lstm_layer_1 = Bidirectional(LSTM(256, return_sequences=True))\n",
    "x1 = lstm_layer_1(inputs1)\n",
    "x2 = lstm_layer_1(inputs2)\n",
    "\n",
    "dropout_layer = Dropout(0.2)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "lstm_layer_2 = LSTM(128)\n",
    "x1 = lstm_layer_2(x1)\n",
    "x2 = lstm_layer_2(x2)\n",
    "\n",
    "dropout_layer = Dropout(0.2)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "dense = Dense(64, activation='relu')\n",
    "x1 = dense(x1)\n",
    "x2 = dense(x2)\n",
    "\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "x = Concatenate(axis=-1)([x1,x2])\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model_1 = Model(inputs=[inputs1, inputs2], outputs=predictions)\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRXboyuNVOZz"
   },
   "outputs": [],
   "source": [
    "filepath=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "GWqpNlV8jbFj",
    "outputId": "ec65705c-4dee-4445-9fdb-f2ba811c2f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 294496 samples, validate on 98166 samples\n",
      "Epoch 1/1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "294496/294496 [==============================] - 6370s 22ms/step - loss: 1.0569 - acc: 0.4321 - val_loss: 1.0425 - val_acc: 0.4599\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.45989, saving model to /content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_1.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ff0fca860>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "model_1.fit(X, to_categorical(y), epochs=1, batch_size=64, verbose=1, validation_split=0.25, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "6HoRl4p4KHno",
    "outputId": "a38e0e6c-8a3a-4fe6-c63b-0cc43e1fc83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.load_weights(filepath, by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v81jxLjoi3K_"
   },
   "source": [
    "#### Predict results and generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "D-UyfmaBjWy_",
    "outputId": "0e5bcfbc-e02a-4444-f333-fae5d181c0ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  ...                                         sentence_2\n",
      "0      0  ...  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...\n",
      "1      1  ...  [[0.41617, 0.0086969, -0.045779, -0.453, 0.396...\n",
      "2      2  ...  [[0.36274, -0.033799, 0.73714, -0.41275, 0.178...\n",
      "3      3  ...  [[0.59766, -0.11836, -0.48428, 0.48654, -0.472...\n",
      "4      4  ...  [[0.23158, 0.69964, 0.43878, -0.31633, 0.18509...\n",
      "\n",
      "[5 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_test = data_from_csv(path_test_no_label, dev_mode=False)\n",
    "\n",
    "data_test_processed = process_dataset(data_test, training=False)\n",
    "print(data_test_processed.head())\n",
    "X = [pad_sequences(data_test_processed['sentence_1'].values, maxlen=80), pad_sequences(data_test_processed['sentence_2'].values, maxlen=80)]\n",
    "\n",
    "assert X[0][0].shape == (80, 50), \"Check shape of your inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "AmQEFg_yjODn",
    "outputId": "40966ed9-ec4b-4e64-d6c3-bf4b69d13840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3359165 , 0.349552  , 0.31453148],\n",
       "       [0.23123178, 0.41849878, 0.35026947],\n",
       "       [0.20817226, 0.39915594, 0.3926718 ],\n",
       "       ...,\n",
       "       [0.43202537, 0.20403525, 0.3639394 ],\n",
       "       [0.36197454, 0.35931134, 0.27871412],\n",
       "       [0.19766548, 0.38119608, 0.42113847]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_1.predict(X)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y78o1Y8jBNn"
   },
   "outputs": [],
   "source": [
    "map_dict = {v: k for k, v in map_dict.items()}\n",
    "gen_csv(predicted, map_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhYE-SBwfvOW"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAbB_i_diWaC"
   },
   "source": [
    "#### Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEWR5-Zmk1yC"
   },
   "outputs": [],
   "source": [
    "# Retrieve Embedded Vectors from Glove\n",
    "glove_wordmap = create_glove_wordmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0XXcwfdk1sa"
   },
   "outputs": [],
   "source": [
    "# Retrieve Dataset from CSV \n",
    "path_train=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_train.csv\"\n",
    "path_test_no_label=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_test_no_labels.csv\"\n",
    "\n",
    "dataset = data_from_csv(path_train, n_dev=5000, dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "etGjzDPpk1mL",
    "outputId": "2e078e9e-5b1e-436b-bb54-6edd5bebe85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ! \n"
     ]
    }
   ],
   "source": [
    "map_dict={'neutral':2, 'entailment':1, 'contradiction':0}\n",
    "dataset_processed = process_dataset(dataset, map_dict=map_dict)\n",
    "print(\"Processed ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "H7FQwRWOk1d_",
    "outputId": "85555e9a-b984-4a18-e5dd-866a17e62921"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116430</th>\n",
       "      <td>116430</td>\n",
       "      <td>[[-0.58475, -0.37703, -0.18568, 0.012511, -0.2...</td>\n",
       "      <td>[[-0.58475, -0.37703, -0.18568, 0.012511, -0.2...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230523</th>\n",
       "      <td>230523</td>\n",
       "      <td>[[-0.90402, -0.5696, -0.42533, 0.10271, 0.1714...</td>\n",
       "      <td>[[0.68938, -0.10644, 0.17083, -0.37583, 0.7517...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127138</th>\n",
       "      <td>127138</td>\n",
       "      <td>[[0.40991, 0.081369, 0.29962, -0.2535, 0.30073...</td>\n",
       "      <td>[[0.61183, -0.22072, -0.10898, -0.052967, 0.50...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210803</th>\n",
       "      <td>210803</td>\n",
       "      <td>[[0.45323, 0.059811, -0.10577, -0.333, 0.72359...</td>\n",
       "      <td>[[-0.20092, -0.060271, -0.61766, -0.8444, 0.57...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384477</th>\n",
       "      <td>384477</td>\n",
       "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
       "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  ... target\n",
       "116430  116430  ...      1\n",
       "230523  230523  ...      2\n",
       "127138  127138  ...      0\n",
       "210803  210803  ...      1\n",
       "384477  384477  ...      0\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz4UdL9Nk1Ra"
   },
   "outputs": [],
   "source": [
    "# On pad ici, sinon ca fait planter la RAM quand on utilise toutes les \n",
    "# lignes du CSV\n",
    "X = [pad_sequences(dataset_processed['sentence_1'].values, maxlen=80), pad_sequences(dataset_processed['sentence_2'].values, maxlen=80)]\n",
    "y = dataset_processed['target'].values\n",
    "\n",
    "# (Nb inputs, nb words, nb dim)\n",
    "assert X[0][0].shape == (80, 50), \"Check the shape of your data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTdbaLF4icXO"
   },
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "jlcyFYhPfx3-",
    "outputId": "f1485559-bc4d-476c-c6d1-5a2f6068c0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           (None, 80, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 512)          628736      input_69[0][0]                   \n",
      "                                                                 input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            multiple             0           bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_6[1][0]            \n",
      "                                                                 dense_61[0][0]                   \n",
      "                                                                 dense_61[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           (None, 80, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 64)           32832       dropout_24[0][0]                 \n",
      "                                                                 dropout_24[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 128)          0           dropout_24[2][0]                 \n",
      "                                                                 dropout_24[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 3)            387         concatenate_30[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 661,955\n",
      "Trainable params: 661,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(80,50))\n",
    "inputs2 = Input(shape=(80,50))\n",
    "\n",
    "lstm_layer_1 = Bidirectional(LSTM(256))\n",
    "x1 = lstm_layer_1(inputs1)\n",
    "x2 = lstm_layer_1(inputs2)\n",
    "\n",
    "dropout_layer = Dropout(0.2)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "dense = Dense(64, activation='relu')\n",
    "x1 = dense(x1)\n",
    "x2 = dense(x2)\n",
    "\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "x = Concatenate(axis=-1)([x1,x2])\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model_2 = Model(inputs=[inputs1, inputs2], outputs=predictions)\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "DAVXj3SHi5KU",
    "outputId": "c7f97207-7145-4b82-a0b1-f1e674313238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 63s 17ms/step - loss: 1.0984 - acc: 0.3643 - val_loss: 1.0936 - val_acc: 0.3728\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37280, saving model to /content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_2.hdf5\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 51s 13ms/step - loss: 1.0913 - acc: 0.3704 - val_loss: 1.0979 - val_acc: 0.3832\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37280 to 0.38320, saving model to /content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_2.hdf5\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 50s 13ms/step - loss: 1.0847 - acc: 0.3845 - val_loss: 1.0907 - val_acc: 0.3648\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.38320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd92748a8d0>"
      ]
     },
     "execution_count": 190,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_2.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "model_2.fit(X, to_categorical(y), epochs=1, batch_size=64, verbose=1, validation_split=0.25, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baHFuZgiimdC"
   },
   "source": [
    "#### Predict results and generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPwOXQGil3Rb"
   },
   "outputs": [],
   "source": [
    "data_test = data_from_csv(path_test_no_label, dev_mode=False)\n",
    "\n",
    "data_test_processed = process_dataset(data_test, training=False)\n",
    "\n",
    "X = [pad_sequences(data_test_processed['sentence_1'].values, maxlen=80), pad_sequences(data_test_processed['sentence_2'].values, maxlen=80)]\n",
    "\n",
    "assert X[0][0].shape == (80, 50), \"Check shape of your inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "XKJqZ1A6mAOh",
    "outputId": "fbd90ab7-da6e-4bfa-f370-2d03c48a1338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37925217, 0.33278218, 0.2879657 ],\n",
       "       [0.30615047, 0.35224319, 0.34160632],\n",
       "       [0.21302755, 0.3802407 , 0.4067317 ],\n",
       "       ...,\n",
       "       [0.44262403, 0.31281003, 0.24456593],\n",
       "       [0.3221449 , 0.3657318 , 0.3121234 ],\n",
       "       [0.34165305, 0.31705436, 0.3412926 ]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_2.predict(X)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ff-rOuJfi9TU"
   },
   "outputs": [],
   "source": [
    "map_dict = {v: k for k, v in map_dict.items()}\n",
    "gen_csv(predicted, map_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLa3kFbpBYe"
   },
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOPg0ksMFwWr"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tw8wT36VpKVT"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def preprocess_model_3(dataset, tokenizer,\n",
    "                       vocab_size = 50000, max_length = 80, \n",
    "                       training=True, \n",
    "                       map_dict={'neutral':2, 'entailment':1, 'contradiction':0}):\n",
    "    \"\"\"\n",
    "        Preprocess data for model_3\n",
    "    \"\"\"\n",
    "     \n",
    "    n_dataset = dataset.copy()\n",
    "    \n",
    "    if training:\n",
    "        tokenizer.fit_on_texts(dataset.sentence_1.values + dataset.sentence_2.values)\n",
    "\n",
    "    sentence1_seq = tokenizer.texts_to_sequences(n_dataset.sentence_1.values)\n",
    "    sentence2_seq = tokenizer.texts_to_sequences(n_dataset.sentence_2.values)\n",
    "    sentence2_seq_padded = pad_sequences(sentence2_seq, maxlen=max_length)\n",
    "    sentence1_seq_padded = pad_sequences(sentence1_seq, maxlen=max_length)\n",
    "\n",
    "    X = [sentence1_seq_padded,sentence2_seq_padded ]\n",
    "    \n",
    "    if training: \n",
    "        y = dataset['label'].replace(map_dict)\n",
    "        return X, y\n",
    "    else: \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfezoetIobZj"
   },
   "outputs": [],
   "source": [
    "# Retrieve Dataset from CSV \n",
    "path_train=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_train.csv\"\n",
    "path_test_no_label=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_test_no_labels.csv\"\n",
    "\n",
    "dataset = data_from_csv(path_train, n_dev=5000, dev_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlslzLHTdg40"
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "map_dict = {'neutral':2, 'entailment':1, 'contradiction':0}\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "max_length = 80\n",
    "\n",
    "X, y = preprocess_model_3(dataset, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvkvGdTjotJe"
   },
   "outputs": [],
   "source": [
    "assert X[0][0].shape == (max_length,), \"Check your input\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLN_7S0XF0hx"
   },
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "XUHSWFIU3Uu1",
    "outputId": "1df50a84-085c-4f5c-de4b-abacc5ad9287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 80, 128)      6400000     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 128)          131584      embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           lstm_4[0][0]                     \n",
      "                                                                 lstm_4[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "                                                                 dropout_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           dropout_6[0][0]                  \n",
      "                                                                 dropout_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            387         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,540,227\n",
      "Trainable params: 6,540,227\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(max_length,))\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 128, input_length=max_length)\n",
    "emb_out1 = embedding_layer(inputs1)\n",
    "emb_out2 = embedding_layer(inputs2)\n",
    "\n",
    "lstm_layer = LSTM(128)\n",
    "x1 = lstm_layer(emb_out1)\n",
    "x2 = lstm_layer(emb_out2)\n",
    "\n",
    "dropout_layer = Dropout(0.3)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "dense = Dense(64, activation='relu')\n",
    "x1 = dense(x1)\n",
    "x2 = dense(x2)\n",
    "\n",
    "dropout_layer = Dropout(0.2)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "x = Concatenate(axis=-1)([x1,x2])\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model_3 = Model(inputs=[inputs1, inputs2], outputs=predictions)\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vd33OMODihHj"
   },
   "outputs": [],
   "source": [
    "filepath=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_3.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhB1zhzh6EK5"
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "model_3.fit(X, to_categorical(y), epochs=2, batch_size=64, verbose=1, validation_split=0.25, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V17OzEOGicvn"
   },
   "outputs": [],
   "source": [
    "model_3.load_weights(filepath, by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_4IbE-CF38f"
   },
   "source": [
    "#### Predict results and generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnZmLTw9Gtt7"
   },
   "outputs": [],
   "source": [
    "data_test = data_from_csv(path_test_no_label, dev_mode=False)\n",
    "\n",
    "X = preprocess_model_3(data_test, tokenizer, training=False)\n",
    "\n",
    "assert X[0][0].shape == (max_length,) and X[1][0].shape == (max_length,), \"Check X dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "-J2AOwLSIBqR",
    "outputId": "463c1556-8e10-4458-b249-89734d9e0e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24822998, 0.35178694, 0.3999831 ],\n",
       "       [0.26851237, 0.34763318, 0.38385442],\n",
       "       [0.09854436, 0.24954228, 0.65191334],\n",
       "       ...,\n",
       "       [0.21078224, 0.10045719, 0.6887606 ],\n",
       "       [0.27909794, 0.2581422 , 0.4627598 ],\n",
       "       [0.08310273, 0.3540999 , 0.5627974 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_3.predict(X)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdoYPBlAI3Bf"
   },
   "outputs": [],
   "source": [
    "map_dict = {v: k for k, v in map_dict.items()}\n",
    "gen_csv(predicted, map_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AiarBjX4F4a1"
   },
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1nUMFe6F4a4"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJXqJBsbF4a4"
   },
   "outputs": [],
   "source": [
    "def preprocess_model_4(dataset, tokenizer,\n",
    "                       vocab_size = 50000, max_length = 80, \n",
    "                       training=True, \n",
    "                       map_dict={'neutral':2, 'entailment':1, 'contradiction':0}):\n",
    "    \"\"\"\n",
    "        Preprocess data for model_4\n",
    "    \"\"\"\n",
    "     \n",
    "    n_dataset = dataset.copy()\n",
    "    \n",
    "    if training:\n",
    "        tokenizer.fit_on_texts(dataset.sentence_1.values + dataset.sentence_2.values)\n",
    "\n",
    "    sentence1_seq = tokenizer.texts_to_sequences(n_dataset.sentence_1.values)\n",
    "    sentence2_seq = tokenizer.texts_to_sequences(n_dataset.sentence_2.values)\n",
    "    sentence2_seq_padded = pad_sequences(sentence2_seq, maxlen=max_length)\n",
    "    sentence1_seq_padded = pad_sequences(sentence1_seq, maxlen=max_length)\n",
    "\n",
    "    X = [sentence1_seq_padded,sentence2_seq_padded ]\n",
    "    \n",
    "    if training: \n",
    "        y = dataset['label'].replace(map_dict)\n",
    "        return X, y\n",
    "    else: \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WViqARMNF4a7"
   },
   "outputs": [],
   "source": [
    "# Retrieve Dataset from CSV \n",
    "path_train=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_train.csv\"\n",
    "path_test_no_label=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/dataset_test_no_labels.csv\"\n",
    "\n",
    "dataset = data_from_csv(path_train, n_dev=5000, dev_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r47fqm2EF4a8"
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "map_dict = {'neutral':2, 'entailment':1, 'contradiction':0}\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "max_length = 80\n",
    "\n",
    "X, y = preprocess_model_4(dataset, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbXCENPhF4a-"
   },
   "outputs": [],
   "source": [
    "assert X[0][0].shape == (max_length,), \"Check your input\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tipVmW-HF4a_"
   },
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "colab_type": "code",
    "id": "7Gz3VPKkF4bA",
    "outputId": "49759a40-0c86-4535-8d1a-3bd2a4ed8a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 80, 128)      6400000     input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 256)          263168      embedding_3[0][0]                \n",
      "                                                                 embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256)          0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           16448       dropout_7[0][0]                  \n",
      "                                                                 dropout_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_7[0][0]                    \n",
      "                                                                 dense_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           dropout_8[0][0]                  \n",
      "                                                                 dropout_8[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            387         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,680,003\n",
      "Trainable params: 6,680,003\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(max_length,))\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 128, input_length=max_length)\n",
    "emb_out1 = embedding_layer(inputs1)\n",
    "emb_out2 = embedding_layer(inputs2)\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(128))\n",
    "x1 = lstm_layer(emb_out1)\n",
    "x2 = lstm_layer(emb_out2)\n",
    "\n",
    "dropout_layer = Dropout(0.3)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "dense = Dense(64, activation='relu')\n",
    "x1 = dense(x1)\n",
    "x2 = dense(x2)\n",
    "\n",
    "dropout_layer = Dropout(0.2)\n",
    "x1 = dropout_layer(x1)\n",
    "x2 = dropout_layer(x2)\n",
    "\n",
    "x = Concatenate(axis=-1)([x1,x2])\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model_4 = Model(inputs=[inputs1, inputs2], outputs=predictions)\n",
    "model_4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdmiTe7iF4bC"
   },
   "outputs": [],
   "source": [
    "filepath=\"/content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_4.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "-Ylbj3WLF4bE",
    "outputId": "e7f475a2-fec2-4fe2-b32e-fb4719fb67d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294496 samples, validate on 98166 samples\n",
      "Epoch 1/2\n",
      "294496/294496 [==============================] - 2090s 7ms/step - loss: 0.9725 - acc: 0.5235 - val_loss: 0.9370 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.54733, saving model to /content/drive/My Drive/MatMax-ING5/Deep Learning/projet_kaggle/data/weights-embedded_4.hdf5\n",
      "Epoch 2/2\n",
      "294496/294496 [==============================] - 2077s 7ms/step - loss: 0.8896 - acc: 0.5860 - val_loss: 0.9463 - val_acc: 0.5463\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.54733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ac2aaacc0>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "model_4.fit(X, to_categorical(y), epochs=2, batch_size=64, verbose=1, validation_split=0.25, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSu7kzLKF4bF"
   },
   "outputs": [],
   "source": [
    "model_4.load_weights(filepath, by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PteQzLIMF4bH"
   },
   "source": [
    "#### Predict results and generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnDLf8swF4bH"
   },
   "outputs": [],
   "source": [
    "data_test = data_from_csv(path_test_no_label, dev_mode=False)\n",
    "\n",
    "X = preprocess_model_3(data_test, tokenizer, training=False)\n",
    "\n",
    "assert X[0][0].shape == (max_length,) and X[1][0].shape == (max_length,), \"Check X dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "WJqySQdHF4bJ",
    "outputId": "1f63335a-c66c-44a2-fcac-ea162b00a0a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3732662 , 0.32626432, 0.30046955],\n",
       "       [0.32090116, 0.26149133, 0.41760755],\n",
       "       [0.0603015 , 0.5184491 , 0.42124936],\n",
       "       ...,\n",
       "       [0.31232375, 0.17211495, 0.5155613 ],\n",
       "       [0.2549939 , 0.37340778, 0.37159833],\n",
       "       [0.05829293, 0.5696199 , 0.3720871 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_4.predict(X)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqKT_7-sF4bL"
   },
   "outputs": [],
   "source": [
    "map_dict = {v: k for k, v in map_dict.items()}\n",
    "gen_csv(predicted, map_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8JnC2S4Uk84e",
    "BZqf4e9RguCp",
    "v81jxLjoi3K_",
    "DhYE-SBwfvOW",
    "oAbB_i_diWaC",
    "LTLa3kFbpBYe",
    "cOPg0ksMFwWr",
    "sLN_7S0XF0hx",
    "AiarBjX4F4a1"
   ],
   "machine_shape": "hm",
   "name": "ModelWithEmbeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
